from loguru import logger
from pymilvus import MilvusClient, DataType


class MilvusRagClient:
    """
    - Milvus Lite æœ¬åœ°å•æ–‡ä»¶ç‰ˆå°è£…ï¼ˆæ–‡ä»¶è·¯å¾„å¦‚ ./milvus.dbï¼‰
    - ä¸“ä¸ºæœ¬åœ° RAG + ollama bge-m3 è®¾è®¡
    - ä½¿ç”¨ pymilvus æœ€æ–°æ¨èå†™æ³•ï¼ˆcreate_schema + prepare_index_paramsï¼‰
    """

    def __init__(self, db_path="./milvus.db"):
        """åˆå§‹åŒ– Milvus Lite å®¢æˆ·ç«¯"""
        self.client = MilvusClient(uri=db_path)
        logger.debug(f"ğŸ‰ Milvus å·²è¿æ¥åˆ° {db_path}")

    def list_collections(self):
        """åˆ—å‡ºå½“å‰æ•°æ®åº“ä¸­æ‰€æœ‰é›†åˆåç§°"""
        return self.client.list_collections()

    def has_collection(self, collection_name: str) -> bool:
        """åˆ¤æ–­æŒ‡å®šé›†åˆæ˜¯å¦å­˜åœ¨"""
        return self.client.has_collection(collection_name)

    def drop_collection(self, collection_name: str):
        """åˆ é™¤æŒ‡å®šé›†åˆï¼ˆè°¨æ…ä½¿ç”¨ï¼‰"""
        if self.has_collection(collection_name):
            self.client.drop_collection(collection_name)
            logger.debug(f"å·²åˆ é™¤é›†åˆ: {collection_name}")
        else:
            logger.warning(f"é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œæ— éœ€åˆ é™¤")

    def create_collection(
        self,
        collection_name: str,
        dim: int = 1024,
        metric_type: str = "IP",
        auto_id: bool = False,
        enable_dynamic: bool = True,
        drop_if_exist: bool = False,
    ) -> bool:
        """
        åˆ›å»ºé›†åˆï¼ˆä½¿ç”¨ç°ä»£ CollectionSchema å†™æ³•ï¼‰
        Args:
            - auto_id=False         è‡ªå·±æä¾›å­—ç¬¦ä¸² idï¼ˆæ¨èç”¨äº RAGï¼Œä¾¿äºè¿½è¸ªæ¥æºï¼‰
            - drop_if_exist=True    å¼€å‘é˜¶æ®µæ–¹ä¾¿é‡ç½®
        """
        if self.has_collection(collection_name):
            if not drop_if_exist:
                logger.warning(f"é›†åˆ {collection_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                return False
            self.drop_collection(collection_name)

        # åˆ›å»º schema
        schema = self.client.create_schema(
            auto_id=auto_id,
            enable_dynamic_field=enable_dynamic,
        )

        # ä¸»é”®ï¼ˆå­—ç¬¦ä¸² idï¼Œé•¿åº¦è¶³å¤Ÿå¤§ï¼‰
        schema.add_field(
            field_name="id",
            datatype=DataType.VARCHAR,
            is_primary=True,
            max_length=65535,
        )

        # å‘é‡å­—æ®µï¼ˆbge-m3 é»˜è®¤ 1024 ç»´ï¼‰
        schema.add_field(
            field_name="vector",
            datatype=DataType.FLOAT_VECTOR,
            dim=dim,
        )

        # åˆ›å»ºé›†åˆ
        self.client.create_collection(
            collection_name=collection_name,
            schema=schema,
        )

        logger.debug(f"é›†åˆåˆ›å»ºæˆåŠŸ: {collection_name}  dim={dim}  metric={metric_type}")
        return True

    def create_index(
        self,
        collection_name: str,
        index_type: str = "IVF_FLAT",
        metric_type: str = "IP",
        nlist: int = 128,
        index_name: str = "vector_idx",
    ):
        """
        åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆä½¿ç”¨ prepare_index_params å†™æ³•ï¼Œå…¼å®¹æ–°ç‰ˆ pymilvusï¼‰
        å¸¸ç”¨å‚æ•°ï¼š
            index_type: "IVF_FLAT", "HNSW", "FLAT"ï¼ˆç²¾ç¡®æœç´¢ï¼‰
            nlist: IVF ç³»åˆ—çš„èšç±»æ•°ï¼Œå°æ•°æ®å»ºè®® 64~256
        """
        if not self.has_collection(collection_name):
            raise ValueError(f"é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºç´¢å¼•")

        index_params = self.client.prepare_index_params()

        # æ ¹æ® index_type è‡ªåŠ¨è®¾ç½® params
        if "IVF" in index_type:
            params = {"nlist": nlist}
        elif index_type == "HNSW":
            params = {"M": 16, "efConstruction": 200}
        else:
            params = {}  # FLAT ç­‰ä¸éœ€è¦é¢å¤–å‚æ•°

        index_params.add_index(
            field_name="vector",
            index_type=index_type,
            metric_type=metric_type,
            params=params,
            index_name=index_name,
        )

        self.client.create_index(
            collection_name=collection_name,
            index_params=index_params,
        )

        logger.debug(f"ç´¢å¼•åˆ›å»ºå®Œæˆ: {collection_name}.vector â†’ " f"{index_type} / {metric_type} (nlist={nlist if 'IVF' in index_type else 'N/A'})")

    def insert(
        self,
        collection_name: str,
        data: list[dict],
        batch_size: int = 1000,
    ) -> dict:
        """
        æ’å…¥æ•°æ®ï¼ˆæ”¯æŒåŠ¨æ€å­—æ®µï¼‰
        data ç¤ºä¾‹ï¼š
        [
            {
                "id": "doc_001_chunk_03",
                "vector": [0.12, -0.34, ..., 0.56],  # 1024ç»´ float list
                "text": "æ®µè½åŸæ–‡...",
                "file_name": "2025åˆåŒ.pdf",
                "chunk_idx": 3,
                "create_time": 1737288000
            },
            ...
        ]
        """
        if not data:
            logger.warning("æ’å…¥æ•°æ®ä¸ºç©º")
            return {"insert_count": 0}

        res = self.client.insert(
            collection_name=collection_name,
            data=data,
            batch_size=batch_size,
        )

        logger.success(f"æ’å…¥å®Œæˆ: {res['insert_count']} æ¡ â†’ {collection_name}")
        return res

    def search(
        self,
        collection_name: str,
        query_vectors: list[list[float]],
        limit: int = 8,
        filter: str | None = None,
        output_fields: list[str] | None = None,
    ) -> list:
        """
        å‘é‡æœç´¢
        query_vectors: [[...], [...]] æ”¯æŒæ‰¹é‡æŸ¥è¯¢
        filter: "file_name like '2025%' and chunk_idx < 100"
        """
        if output_fields is None:
            output_fields = ["*"]

        results = self.client.search(
            collection_name=collection_name,
            data=query_vectors,
            limit=limit,
            filter=filter,
            output_fields=output_fields,
        )

        return results

    def find_docs(
        self,
        collection_name: str,
        query_vectors: list[list[float]],
        limit: int = 5,
        output_fields: list[str] | None = None,
        return_fields: list[str] | None = None,
        filter: str | None = None,
    ) -> list:
        """
        æŸ¥æ‰¾æ–‡æ¡£
        Args:
            collection_name: é›†åˆåç§°
            query_vectors: æŸ¥è¯¢å‘é‡
            limit: è¿”å›çš„æ–‡æ¡£æ•°é‡
            output_fields: æ£€ç´¢è¿”å›çš„å­—æ®µ
            return_fields: å®é™…è¿”å›çš„å­—æ®µ
            filter: è¿‡æ»¤æ¡ä»¶
        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        hits = self.search(
            collection_name=collection_name,
            query_vectors=query_vectors,
            limit=limit,
            output_fields=output_fields,
            filter=filter,
        )

        if hits and len(hits) > 0 and len(hits[0]) > 0:
            docs = []
            for hit in hits[0]:
                ent = hit["entity"]
                if return_fields is None:
                    doc = ent
                else:
                    doc = {field: ent.get(field) for field in return_fields if field in ent}
                docs.append(doc)
            return docs
        else:
            return []


if __name__ == "__main__":
    import ollama

    client = MilvusRagClient(db_path="./milvus.db")
    COLLECTION = "test1"
    DIM = 1024

    # 1. åˆ›å»ºé›†åˆï¼ˆå¼€å‘æ—¶å¯å¼ºåˆ¶é‡å»ºï¼‰
    client.create_collection(
        collection_name=COLLECTION,
        dim=DIM,
        metric_type="COSINE",
        auto_id=False,
        drop_if_exist=True,
    )

    # 2. åˆ›å»ºç´¢å¼•
    client.create_index(
        collection_name=COLLECTION,
        metric_type="COSINE",
    )

    # 3. å‡†å¤‡æ’å…¥æ•°æ®
    sample_texts = [
        "é¦™æ¸¯ç»´æ¸¯å¤œæ™¯åœ¨èŠ‚å‡æ—¥ä¼šæœ‰çƒŸèŠ±è¡¨æ¼”ï¼Œéå¸¸æµªæ¼«ã€‚",
        "2026 å¹´å¤§æ¨¡å‹åœ¨æœ¬åœ°éƒ¨ç½²çš„æˆæœ¬å·²ç»å¤§å¹…ä¸‹é™ã€‚",
        "bge-m3 æ”¯æŒå¤šè¯­è¨€ã€é•¿æ–‡æœ¬å’Œç¨€ç–å‘é‡æ£€ç´¢ã€‚",
        "Milvus Lite éå¸¸é€‚åˆä¸ªäººç”µè„‘è·‘å°å‹çŸ¥è¯†åº“ã€‚",
        "å…¨çƒé¡¶å°–å¤§æ¨¡å‹æœ‰å“ªäº›ï¼Ÿ",
        "ä½ ç”¨çš„ä»€ä¹ˆæ¨¡å‹ï¼Ÿ",
    ]

    insert_data = []
    for idx, txt in enumerate(sample_texts):
        emb = ollama.embeddings(model="bge-m3", prompt=txt)["embedding"]

        insert_data.append(
            {
                "id": f"demo_{idx:03d}",
                "vector": emb,
                "text": txt,
                "source": "2.md" if idx % 2 == 0 else "1.md",
                "seq": idx,
            }
        )

    # 4. æ’å…¥
    client.insert(COLLECTION, insert_data)

    # 5. æœç´¢ç¤ºä¾‹
    query = "å¤§æ¨¡å‹"
    query_emb = ollama.embeddings(model="bge-m3", prompt=query)["embedding"]

    hits = client.search(
        collection_name=COLLECTION,
        query_vectors=[query_emb],
        limit=5,
        output_fields=["id", "text", "source", "seq"],
        filter="source == '1.md'",
    )

    print("\n=== æœç´¢ç»“æœ ===")
    if hits and len(hits) > 0 and len(hits[0]) > 0:
        for rank, hit in enumerate(hits[0], 1):
            ent = hit["entity"]
            print(f"  {rank:2}. score={hit['distance']:.4f}")
            print(f"     id    : {hit['id']}")
            print(f"     text  : {ent.get('text','')[:80]}...")
            print(f"     source: {ent.get('source','N/A')}")
            print()
    else:
        print("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ç»“æœ")
